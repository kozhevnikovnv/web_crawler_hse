<!DOCTYPE html>
<html lang="en">
<head>
<title>Регрессия как задача машинного обучения</title>
<meta charset="utf-8"/>
<link href="/assets/css/main.css" rel="stylesheet"/>
<meta content="width=device-width, initial-scale=1, viewport-fit=cover" name="viewport"/>
<link href="/assets/shower/themes/ribbon/styles/styles.css" rel="stylesheet"/>
<style>
        .shower {
            --slide-ratio: calc(16 / 12);
        }
    </style>
<style>

        html{
            background-color: #000;
        }

        body{
            min-height: 0;
            background-color: #000;
        }

        #cover h2 {
            margin: 30px 0 0;
            /*color: white;*/
            text-align: center;
            font-size: 70px;
        }

        #cover p {
            margin: 10px 0 0;
            text-align: center;
            color: white;
            font-style: italic;
            font-size: 12px;
        }

        #cover p a {
            /*color: white;*/
        }

        #temp {
            display: none;
            visibility: hidden;
        }

        section {
            font-size: 20px;
        }

        section h2 {
            font-size: 50px;
        }

        .slide{
            line-height: 1.2em;
            font-size: 1em;
        }

        .slide ol, .slide ul {
            line-height: 1em;
        }

        .slide pre {
            overflow-x: hidden; 
            overflow-y: hidden; 
            line-height: 1.2em;
            /*font-size: 1em;*/
        }

        img {
            max-height: 550px;
            width: auto;
        }

        img#cover{
            height: 100%;
            width: auto;
        }

        .slide .shout {
            font-size: 120px;
        }

        .mjx-chtml{
        	font-size: 25px !important;
        }

        section > div.presentation, section > img{
		  margin: 0;
		  position: absolute;
		  top: 460px;
		  left: 50%;
		  -ms-transform: translate(-50%, -50%);
		  transform: translate(-50%, -50%);
		}
    </style>
<script async="" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML" type="text/javascript">
</script>
<script type="text/x-mathjax-config">
	   MathJax.Hub.Config({
	     extensions: ["tex2jax.js"],
	     jax: ["input/TeX", "output/HTML-CSS"],
	     tex2jax: {
	       inlineMath: [ ['$','$'], ["\\(","\\)"] ],
	       displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
	       processEscapes: true
	     },
	     "HTML-CSS": { availableFonts: ["TeX"] }
	   });
	</script>
</head>
<body class="shower list">
<div id="temp">
<h3 id="постановка-задачи-регрессии">Постановка задачи регрессии</h3>
<p style="text-align: center; font-size:0.7em;"><img alt="Задача регрессии" class="align-center" src="/assets/images/ml_text/ml1-15.png" style="width: 50%;" title="Задача регрессии"/>
Источник: <a href="https://www.google.com/url?sa=i&amp;url=https%3A%2F%2Fwww.analyticsvidhya.com%2Fblog%2F2021%2F05%2F5-regression-algorithms-you-should-know-introductory-guide%2F&amp;psig=AOvVaw2c_ybzX_oF5s5EZjCsWfH0&amp;ust=1651764035488000&amp;source=images&amp;cd=vfe&amp;ved=0CAwQjRxqFwoTCLiPvfSSxvcCFQAAAAAdAAAAABAD">Analytics Vidhya</a>.</p>
<p>Задача регрессии - это одна из основных задач машинного обучения. И хотя, большинство задач на практике относятся к другому типу - классификации, мы начнем знакомство с машинным обучением именно с регрессии. Регрессионные модели были известны задолго до появления машинного обучения как отрасли и активно применяются в статистике, эконометрике, математическом моделировании. Машинное обучение предлагает новый взгляд на уже известные модели. И этот новый взгляд позволит строить более сложные и мощные модели, чем классические математические дисциплины.</p>
<p>Задача регрессии относится к категории задач обучения с учителем. Это значит, что в наборе данных, который используется для обучения, должен иметь определенную структуру. Обычно, наборы данных для машинного обучения представляют собой таблицу, в которой по строкам перечислены разные объекты наблюдений или измерений. В столбцах - различные характеристики, или атрибуты, объектов. А на пересечении строк и столбцов - значение данной характеристики у данного объекта. Обычно один атрибут (или переменная) имеет особый характер - именно ее значение мы и хотим научиться предсказывать с помощью модели машинного обучения. Эта характеристика объекта называется целевая переменная. И если эта целевая переменная выражена числом (а точнее, некоторой непрерывной величиной) - то мы говорим о задаче регрессии.</p>
<p>Задачи регрессии на практике встречаются довольно часто. Например, предсказание цены объекта недвижимости - классическая регрессионная задача. В таких проблемах атрибутами выступают разные характеристики квартир или домов - площадь, этажность, расположение, расстояние до центра города, количество комнат, год постройки. В разных наборах данных собрана разная информация И, соответственно, модели тоже должны быть разные. Другой пример - предсказание цены акций или других финансовых активов. Или предсказание температуры завтрашним днем.</p>
<p>Во всех таких задачах нам нужно иметь данные, которые позволят осуществить такое предсказание. Да, “предсказание” - это условный термин, не всегда мы говорим о будущих событиях. Регрессионные модели используют информацию об объектах в обучающем наборе данных, чтобы сделать вывод о возможном значении целевой переменной. И для этого нужно, чтобы ее значение имело какую-то зависимость от имеющихся у нас атрибутов. Если построить модель предсказания цены акции, но на вход подать информацию о футбольных матчах - ничего не получится. Мы предполагаем, что в наборе данных собраны именно те атрибуты объектов, которые имеют влияние на на значение целевой переменной. И чем больше это предположение выполняется, тем точнее будет потенциально наша модель.</p>
<p>Немного поговорим о терминах. Набор данных который мы используем для обучения модели называют датасетом (dataset) или обучающей выборкой (training set). Объекты, которые описываются в датасете еще называют точками данных (data points). Целевую переменную еще называют на статистический манер зависимой переменной (dependent variable) или результативной, выходной (output), а остальные атрибуты - независимыми переменными (dependent variables), или признаками (features), или факторами, или входными переменными (input). Значения одного конкретного атрибута для всех объектов обучающей выборки часто представляют как вектор этого признака (feature vector). А всю таблицу всех атрибутов называют матрицей атрибутов (feature matrix). Соответственно, еще есть вектор целевой переменной, он не входит в матрицу атрибутов.</p>
<p>С точки зрения информатики, регрессионная модель - это функция, которая принимает на вход значения атрибутов какого-то конкретного объекта и выдает на выходе предполагаемое значение целевой переменной. В большинстве случаев мы предполагаем, что целевая переменная у нас одна. Если стоит задача предсказания нескольких характеристик, то их чаще воспринимают как несколько независимых задач регрессии на одних и тех же атрибутах.</p>
<p>Мы пока ничего не говорили о том, как изнутри устроена регрессионная модель. Это потому, что она может быть какой угодно. Это может быть математическое выражение, условный алгоритм, сложная программа со множеством ветвлений и циклов, нейронная сеть - все это можно представить регрессионной моделью. Единственное требование к модели машинного обучения - она должна быть параметрической. То есть иметь какие-то внутренние параметры, от которых тоже зависит результат вычисления. В простых случаях, чаще всего в качестве регрессионной модели используют аналитические функции. Таких функций бесконечное количество, но чаще всего используется самая простая функция, с которой мы и начнем изучение регрессии - линейная функция.</p>
<p>Так же надо сказать, что иногда регрессионные модели подразделяют на парную и множественную регрессии. Парная регрессия - это когда у нас всего один атрибут. Множественная - когда больше одного. Конечно, на практике парная регрессия почти не встречается, но на примере такой простой модели мы поймем основные концепции машинного обучения. Плюс, парную регрессию очень удобно и наглядно можно изобразить на графике. Когда у нас больше двух переменных, графики уже не особо построишь, и модели приходится визуализировать иначе, более косвенно.</p>
<div class="notice--info">
<p>Выводы:</p>
<ol>
<li>Регрессия - это задача машинного обучения с учителем, которая заключается в предсказании некоторой непрерывной величины.</li>
<li>Для использования регрессионных моделей нужно, чтобы в датасете были характеристики объектов и “правильные” значения целевой переменной.</li>
<li>Примеры регрессионных задач - предсказание цены акции, оценка цены объекта недвижимости.</li>
<li>Задача регрессии основывается на предположении, что значение целевой переменной зависит от значения признаков.</li>
<li>Регрессионная модель принимает набор значений и выдает предсказание значения целевой переменной.</li>
<li>В качестве регрессионных моделей часто берут аналитические функции, например, линейную.</li>
</ol>
</div>
<h3 id="линейная-регрессия-с-одной-переменной">Линейная регрессия с одной переменной</h3>
<h4 id="функция-гипотезы">Функция гипотезы</h4>
<p style="text-align: center; font-size:0.7em;"><img alt="Модель регрессии" class="align-center" src="/assets/images/ml_text/ml1-1.png" style="width: 30%;" title="Модель регрессии"/></p>
<p>Напомним, что в задачах регрессии мы принимаем входные переменные и пытаемся получить более-менее достоверное значение целевой переменной. Ведь любая функция, даже самая простая линейная может выдавать совершенно разные значения для одних и тех же входных данных, если в функции будут разные параметры. Поэтому, любая регрессионная модель - это не какая-то конкретная математическая функция, а целое семейство функций. И задача алгоритма обучения - подобрать значения параметров таким образом, чтобы для объектов обучающей выборки, для которых мы уже знаем правильные ответы, предсказанные (или теоретические, вычисленные из модели) значения были как можно ближе к тем, которые есть в датасете (эмпирические, истинные значения).</p>
<p>Парная, или одномерная (univariate) регрессия используется, когда вы хотите предсказать одно выходное значение (чаще всего обозначаемое $y$), зависящее от одного входного значения (обычно обозначается $x$). Сама функция называется функцией гипотезы или моделью. В качестве функции гипотезы для парной регрессии можно выбрать любую функцию, но мы пока потренируемся с самой простой функцией одной переменной - линейной функцией. Тогда нашу модель можно назвать парной линейной регрессией.</p>
<p>В случае парной линейной регрессии функция гипотезы имеет следующий общий вид:</p>
<div class="presentation">
\[\hat{y} = h_b (x) = b_0 + b_1 x\]
</div>
<p>Обратите внимание, что это похоже на уравнение прямой. Эта модель соответствует множеству всех возможных прямых на плоскости. Когда мы конкретизируем модель значениями параметров (в данном случае - $b_0$ и $b_0$), мы получаем конкретную прямую. И наша задача состоит в том, чтобы выбрать такую прямую, которая бы лучше всего “легла” в точки из нашей обучающей выборки.</p>
<p>В данном случае, мы пытаемся подобрать функцию <em>h(x)</em> таким образом, чтобы отобразить данные нам значения <em>x</em> в данные значения <em>y</em>.</p>
<p>Допустим, мы имеем следующий обучающий набор данных:</p>
<table>
<tr>
<td>входная переменная x
   </td>
<td>выходная переменная y
   </td>
</tr>
<tr>
<td>0
   </td>
<td>4
   </td>
</tr>
<tr>
<td>1
   </td>
<td>7
   </td>
</tr>
<tr>
<td>2
   </td>
<td>7
   </td>
</tr>
<tr>
<td>3
   </td>
<td>8
   </td>
</tr>
</table>
<p>Мы можем составить случайную гипотезу с параметрами $ b_0 = 2, b_1 = 2 $. Тогда для входного значения $ x=1, y=4 $, что на 3 меньше данного. Задача регрессии состоит в нахождении таких параметров функции гипотезы, чтобы она отображала входные значения в выходные как можно более точно, или, другими словами, описывала линию, наиболее точно ложащуюся в данные точки на плоскости (x, y).</p>
<div class="notice--info">
<p>Выводы:</p>
<ol>
<li>Модель машинного обучения - это параметрическая функция.</li>
<li>Задача обучения состоит в том, чтобы подобрать параметры модели таким образом, чтобы она лучше всего описывала обучающие данные.</li>
<li>Парная линейная регрессия работает, если есть всего одна входящая переменная.</li>
<li>Парная линейная регрессия - одна из самых простых моделей машинного обучения.</li>
<li>Парная линейная регрессия соответствует множеству всех прямых на плоскости. Из них мы выбираем одну, наиболее подходящую.</li>
</ol>
</div>
<h4 id="функция-ошибки">Функция ошибки</h4>
<p>Как мы уже говорили, разные значения параметров дают разные модели. Для того, чтобы подобрать наилучшую модель, нам нужно средство измерения “точности” модели, некоторая функция, которая показывает, насколько модель хорошо или плохо соответствует имеющимся данным.</p>
<p style="text-align: center; font-size:0.7em;"><img alt="Разные модели" class="align-center" src="/assets/images/ml_text/ml1-2.png" style="width: 800px;" title="Разные модели"/></p>
<p>В простых случаях мы можем отличить хорошие модели от плохих, только взглянув на график. Но это затруднительно, если количество признаков очень велико, если модели лишь немного отличаются друг от друга. Да и для автоматизации процесса нужен способ формализовать наше общее представление о том, что модель “ложится” в точки данных.</p>
<p>Такая функция называется функцией ошибки (cost function). Она измеряет отклонения теоретических значений (то есть тех, которые предсказывает модель) от эмпирических (то есть тех, которые есть в данных). Чем выше значение функции ошибки, тем хуже модель соответствует имеющимся данным, хуже описывает их. Если модель полностью соответствует данным, то значение функции ошибки будет нулевым.</p>
<p style="text-align: center; font-size:0.7em;"><img alt="Отклонения значений" class="align-center" src="/assets/images/ml_text/ml1-3.png" style="width: 50%;" title="Отклонения значений"/></p>
<p>В задачах регрессии в качестве функции ошибки чаще всего берут среднеквадратичное отклонение теоретических значений от эмпирических. То есть сумму квадратов отклонений, деленная на удвоенное количество измерений.</p>
<div class="presentation">
\[J(b_0, b_1) 
= \frac{1}{2m} \sum_{i=1}^{m} (\hat{y_i} - y_i)^2 
= \frac{1}{2m} \sum_{i=1}^{m} (h_b(x_i) - y_i)^2\]
</div>
<p>Эту функцию называют «функцией квадрата ошибки» или «среднеквадратичной ошибкой» (mean squared error, MSE). Среднее значение уменьшено вдвое для удобства вычисления градиентного спуска, так как производная квадратичной функции будет отменять множитель 1/2. Вообще, функцию ошибки можно свободно домножить или разделить на любое число (положительное), ведь нам не важна конкретная величина этой функции. Нам важно, что какие-то модели (то есть наборы значений параметров модели) имеют низкую ошибку, они нам подходят больше, а какие-то - высокую ошибку, они подходят нам меньше.</p>
<p>Возведение в квадрат в этой формуле нужно для того, чтобы положительные отклонения не компенсировали отрицательные. Можно было бы для этого брать, например, абсолютное значение, но эта функция не везде дифференцируема, а это станет нам важно позднее.</p>
<p>Обратите внимание, что в качестве аргументов у функции ошибки выступают параметры нашей функции гипотезы. Ведь функция ошибки оценивает отклонение конкретной функции гипотезы (то есть набора значений параметров этой функции) от эмпирических значений, то есть ставит в соответствие каждому набору параметров модели число, характеризующее ошибку этого набора.</p>
<p>Давайте проследим формирование функции ошибки на еще более простом примере. Возьмем упрощенную форму линейной модели - прямую пропорциональность. Она выражается формулой:</p>
<div class="presentation">
\[\hat{y} = h_b (x) = b_1 x\]
</div>
<p>Эта модель поможет нам, так как у нее всего один параметр. И функцию ошибки можно будет изобразить на плоскости. Возьмем фиксированный набор точек и попробуем несколько значений параметра для вычисления функции ошибки. Слева на графике изображены точки данных и текущая функция гипотезы, а на правом графике бы будем отмечать значение использованного параметра (по горизонтали) и получившуюся величину функции ошибки (по вертикали):</p>
<p><img alt="Функция ошибки одной переменной" class="align-center" src="/assets/images/ml_text/ml1-16.png" style="width: 50%;" title="Функция ошибки одной переменной"/></p>
<p><img alt="Функция ошибки одной переменной" class="align-center" src="/assets/images/ml_text/ml1-17.png" style="width: 50%;" title="Функция ошибки одной переменной"/></p>
<p><img alt="Функция ошибки одной переменной" class="align-center" src="/assets/images/ml_text/ml1-18.png" style="width: 50%;" title="Функция ошибки одной переменной"/></p>
<p><img alt="Функция ошибки одной переменной" class="align-center" src="/assets/images/ml_text/ml1-19.png" style="width: 50%;" title="Функция ошибки одной переменной"/></p>
<p><img alt="Функция ошибки одной переменной" class="align-center" src="/assets/images/ml_text/ml1-20.png" style="width: 50%;" title="Функция ошибки одной переменной"/></p>
<p>На этом примере мы видим еще одно преимущество возведения в квадрат - это то, что такая функция в простых случаях имеет один глобальный минимум. На правом графике формируется точка за точкой некоторая функция, которая похожа очертаниями на параболу. Но мы не знаем аналитического вида этой параболы, мы можем лишь строить ее точка за точкой.</p>
<p>В нашем примере, в определенной точке функция ошибки обращается в ноль. Это соответствует “идеальной” функции гипотезы. То есть такой, когда она проходит четко через все точки. В нашем примере это стало возможно благодаря тому, что точки данных и так располагаются на одной прямой. В общем случае это не выполняется и функция ошибки, вообще говоря, не обязана иметь нули. Но она должна иметь глобальный минимум. Рассмотрим такой неидеальный случай:</p>
<p><img alt="Функция ошибки одной переменной" class="align-center" src="/assets/images/ml_text/ml1-21.png" style="width: 50%;" title="Функция ошибки одной переменной"/></p>
<p><img alt="Функция ошибки одной переменной" class="align-center" src="/assets/images/ml_text/ml1-22.png" style="width: 50%;" title="Функция ошибки одной переменной"/></p>
<p><img alt="Функция ошибки одной переменной" class="align-center" src="/assets/images/ml_text/ml1-23.png" style="width: 50%;" title="Функция ошибки одной переменной"/></p>
<p><img alt="Функция ошибки одной переменной" class="align-center" src="/assets/images/ml_text/ml1-24.png" style="width: 50%;" title="Функция ошибки одной переменной"/></p>
<p><img alt="Функция ошибки одной переменной" class="align-center" src="/assets/images/ml_text/ml1-25.png" style="width: 50%;" title="Функция ошибки одной переменной"/></p>
<p>Какое бы значение параметра мы не использовали, линейная функция неспособна идеально пройти через такие три точки, которые не лежат на одной прямой. Эта ситуация называется “недообучение”, об этом мы еще будем говорить дальше. Это значит, что наша модель слишком простая, чтобы идеально описать данные. Но зачастую, идеальная модель и не требуется. Важно лишь найти наилучшую модель из данного класса (например, линейных функций).</p>
<p>Выше мы рассмотрели упрощенный пример с функцией гипотезы с одним параметром. Но у парной линейной регрессии же два параметра. В таком случае, функция ошибки будет описывать не параболу, а параболоид:</p>
<p><img alt="Среднеквадратическая ошибка" class="align-center" src="/assets/images/ml_text/ml1-4.png" style="width: 50%;" title="Среднеквадратическая ошибка"/></p>
<p>Теперь мы можем конкретно измерить точность нашей предсказывающей функции по сравнению с правильными результатами, которые мы имеем, чтобы мы могли предсказать новые результаты, которых у нас нет.</p>
<p>Если мы попытаемся представить это наглядно, наш набор данных обучения будет разбросан по плоскости x-y. Мы пытаемся подобрать прямую линию, которая проходит через этот разбросанный набор данных. Наша цель - получить наилучшую возможную линию. Лучшая линия будет такой, чтобы средние квадраты вертикальных расстояний рассеянных точек от линии были наименьшими. В лучшем случае линия должна проходить через все точки нашего набора данных обучения. В таком случае значение J будет равно 0.</p>
<p><img alt="Ошибка" class="align-center" src="/assets/images/ml_text/ml1-5.png" style="width: 50%;" title="Ошибка"/></p>
<p><img alt="Ошибка" class="align-center" src="/assets/images/ml_text/ml1-6.png" style="width: 50%;" title="Ошибка"/></p>
<p>В более сложных моделях параметров может быть еще больше, но это не важно, ведь нам не нужно строить функцию ошибки, нам нужно лишь оптимизировать ее.</p>
<div class="notice--info">
<p>Выводы:</p>
<ol>
<li>Функция ошибки нужна для того, чтобы отличать хорошие модели от плохих.</li>
<li>Функция ошибки показывает численно, насколько модель хорошо описывает данные.</li>
<li>Аргументами функции ошибки являются параметры модели, ошибка зависит от них.</li>
<li>Само значение функции ошибки не несет никакого смысла, оно используется только в сравнении.</li>
<li>Цель алгоритма машинного обучения - минимизировать функцию ошибки, то есть найти такой набор параметров модели, при которых ошибка минимальна.</li>
<li>Чаще всего используется так называемая L2-ошибка - средний квадрат отклонений теоретических значений от эмпирических (метрика MSE).</li>
</ol>
</div>
<h4 id="метод-градиентного-спуска">Метод градиентного спуска</h4>
<p>Таким образом, у нас есть  функция гипотезы, и  способ оценить, насколько хорошо конкретная гипотеза вписывается в данные. Теперь нам нужно подобрать параметры функции гипотезы. Вот где приходит на помощь метод градиентного спуска.</p>
<p>Это происходит при помощи производной функции ошибки. Необходимое условие минимума функции - обращение в ноль ее производной. А так как мы знаем, что квадратичная функция имеет один глобальный экстремум - минимум, то наша задача очень проста - вычислить производную функции ошибки и найти, где она равна нулю.</p>
<p>Давайте найдем производную среднеквадратической функции ошибки:</p>
<div class="presentation">
\[J(b_0, b_1) = \frac{1}{2m} \sum_{i=1}^{m} (h_b(x_i) - y_i)^2\]
</div>
<div class="presentation">
\[J(b_0, b_1) = \frac{1}{2m} \sum_{i=1}^{m} (h_b(x_i) - y_i)^2\]

\[\frac{\partial}{\partial b_i} J = 
\frac{1}{m} \sum_{i=1}^{m} (h_b(x_i) - y^{(i)}) \cdot \frac{\partial}{\partial b_i} h_b(x_i)\]
</div>
<div class="presentation">
\[J(b_0, b_1) = \frac{1}{2m} \sum_{i=1}^{m} (b_0 + b_1 x_i - y_i)^2\]

\[\frac{\partial J}{\partial b_0} = 
\frac{1}{m} \sum (b_0 + b_1 x_i - y_i) = 
\frac{1}{m} \sum (h_b(x_i) - y_i)\]

\[\frac{\partial J}{\partial b_1} = 
\frac{1}{m} \sum (b_0 + b_1 x_i - y_i) \cdot x_i = 
\frac{1}{m} \sum (h_b(x_i) - y_i) \cdot x_i\]

</div>
<p>Проблема в том, что мы не можем просто решить эти уравнения аналитически. Ведь мы не знаем общий вид функции ошибки, не то, что ее производной. Ведь он зависит, от всех точек данных. Но мы можем вычислить эту функцию (и ее производную) в любой точке. А точка на этой функции - это конкретный набор значений параметров модели. Поэтому пришлось изобрести численный алгоритм. Он работает следующим образом.</p>
<p>Сначала, мы выбираем произвольное значение параметров модели. То есть, произвольную точку в области определения функции. Мы не знаем, является ли эта точка оптимальной (скорее нет), не знаем, насколько она далека от оптимума. Но мы можем вычислить направление к оптимуму. Ведь мы знаем наклон касательной к графику функции ошибки.</p>
<p><img alt="Градиентный спуск" class="align-center" src="/assets/images/ml_text/ml1-26.png" style="width: 50%;" title="Градиентный спуск"/></p>
<p>Наклон касательной является производной в этой точке, и это даст нам направление движения в сторону самого крутого уменьшения значения функции. Если представить себе функцию одной переменной (параболу), то там все очень просто. Если производная в точке отрицательна, значит функция убывает, значит, что оптимум находится справа от данной точки. То есть, чтобы приблизиться к оптимуму надо увеличить аргумент функции. Если же производная положительна, то все наоборот - функция возрастает, оптимум находится слева и нам нужно уменьшить значение аргумента. Причем, чем дальше от оптимума, тем быстрее возрастает или убывает функция. То есть значение производной дает нам не только направление, но и величину нужного шага. Сделав шаг, пропорциональный величине производной и в направлении, противоположном ей, можно повторить процесс и еще больше приблизиться к оптимуму. С каждой итерацией мы будем приближаться к минимуму ошибки и математически доказано, что мы можем приблизиться к ней произвольно близко. То есть, данный метод сходится в пределе.</p>
<p>В случае с функцией нескольких переменных все немного сложнее, но принцип остается прежним. Только мы оперируем не полной производной функции, а вектором частных производных по каждому параметру. Он задает нам направление максимального увеличения функции. Чтобы получить направление максимального спада функции нужно просто домножить этот вектор на -1. После этого нужно обновить значения каждого компонента вектора параметров модели на величину, пропорциональную соответствующему компоненту вектора градиента. Таким образом мы делаем шаги вниз по функции ошибки в направлении с самым крутым спуском, а размер каждого шага пропорционален определяется параметром α, который называется скоростью обучения.</p>
<div class="presentation">
<p>Алгоритм градиентного спуска:</p>
<p>повторяйте до сходимости:</p>

\[b_j := b_j - \alpha \frac{\partial}{\partial b_j} J(b_0, b_1)\]
</div>
<p>где j=0,1 - представляет собой индекс номера признака.</p>
<p>Это общий алгоритм градиентного спуска. Она работает для любых моделей и для любых функций ошибки. Это итеративный алгоритм, который сходится в пределе. То есть, мы никогда не придем в сам оптимум, но можем приблизиться к нему сколь угодно близко. На практике нам не так уж важно получить точное решение, достаточно решения с определенной точностью.</p>
<p>Алгоритм градиентного спуска имеет один параметр - скорость обучения. Он влияет на то, как быстро мы будем приближаться к оптимуму. Кажется, что чем быстрее, тем лучше, но оказывается, что если значение данного параметра слишком велико, то мы буем постоянно промахиваться и алгоритм будет расходиться. Более подробно об этом параметре мы поговорим в практической работе.</p>
<p><img alt="Градиентный спуск" class="align-center" src="/assets/images/ml_text/ml1-27.png" style="width: 80%;" title="Градиентный спуск"/></p>
<div class="presentation">
<p>Алгоритм градиентного спуска для парной линейной регрессии:</p>
<p>повторяйте до сходимости:</p>

\[b_0 := b_0 - \alpha \frac{1}{m} \sum_{i=1}^{m} (h_b(x^{(i)} )- y^{(i)})\]

\[b_1 := b_1 - \alpha \frac{1}{m} \sum_{i=1}^{m} (h_b(x^{(i)}) - y^{(i)}) \cdot x^{(i)}\]
</div>
<p>На практике “повторяйте до сходимости” означает, что мы повторяем алгоритм градиентного спуска до тех пор, пока значение функции ошибки не перестанет значимо изменяться. Это будет означать, что мы уже достаточно близко к минимуму и дальнейшие шаги градиентного спуска слишком малы, чтобы быть целесообразными. Конечно, это оценочное суждение, но на практике обычно, нескольких значащих цифр достаточно для практического применения моделей машинного обучения.</p>
<p>Алгоритм градиентного спуска имеет одну особенность, про которую нужно помнить. Он в состоянии находить только локальный минимум функции. Он в принципе, по своей природе, локален. Поэтому, если функция ошибки будет очень сложна и иметь несколько локальных оптимумов, то результат работы градиентного спуска будет зависеть от выбора начальной точки:</p>
<p><img alt="Спуск" class="align-center" src="/assets/images/ml_text/ml1-7.png" style="width: 50%;" title="Спуск"/></p>
<p><img alt="Другой спуск" class="align-center" src="/assets/images/ml_text/ml1-8.png" style="width: 50%;" title="Другой спуск"/></p>
<p>На практике эту проблему решают методом семплирования - запускают градиентный спуск из множества случайных точек и выбирают то минимум, который оказался меньше по значению функции ошибки. Но этот подход понадобится нам при рассмотрении более сложных и глубоких моделей машинного обучения. Для простых линейных, полиномиальных и других моделей метод градиентного спуска работает прекрасно. В настоящее время этот алгоритм - это основная рабочая лошадка классических моделей машинного обучения.</p>
<div class="notice--info">
<p>Выводы:</p>
<ol>
<li>Метод градиентного спуска нужен, чтобы найти минимум функции, если мы не можем ее вычислить аналитически.</li>
<li>Это численный итеративный алгоритм локальной оптимизации.</li>
<li>Для запуска градиентного спуска нужно знать частную производную функции ошибки.</li>
<li>Для начала мы берем произвольные значения параметров, затем обновляем их по данной формуле.</li>
<li>Доказано, что этот метод сходится к локальному минимуму.</li>
<li>Если функция ошибки достаточно сложная, то разные начальные точки дадут разный результат.</li>
<li>Метод градиентного спуска имеет свой параметр - скорость обучения. Обычно его подстаивают автоматически.</li>
<li>Метод градиентного спуска повторяют много раз до тех пор, пока функция ошибки не перестанет значимо изменяться.</li>
</ol>
</div>
<h3 id="регрессия-с-несколькими-переменными">Регрессия с несколькими переменными</h3>
<h4 id="множественная-линейная-регрессия">Множественная линейная регрессия</h4>
<p style="text-align: center; font-size:0.7em;"><img alt="Множественная регрессия" class="align-center" src="/assets/images/ml_text/ml1-9.png" style="width: 800px;" title="Множественная регрессия"/></p>
<p>Парная регрессия, как мы увидели выше, имеет дело с объектами, которые характеризуются одним числовым признаком (<em>x</em>). На практике, конечно, объекты характеризуются несколькими признаками, а значит в модели должна быть не одна входящая переменная, а несколько (или, что то же самое, вектор). Линейная регрессия с несколькими переменными также известна как «множественная линейная регрессия». Введем обозначения для уравнений, где мы можем иметь любое количество входных переменных:</p>
<p>$ x^{(i)} $- вектор-столбец всех значений признаков i-го обучающего примера;</p>
<p>$ x_j^{(i)} $ - значение j-го признака i-го обучающего примера;</p>
<p>$ x_j $ - вектор j-го признака всех обучающих примеров;</p>
<p><em>m</em> - количество примеров в обучающей выборке;</p>
<p><em>n</em> - количество признаков;</p>
<p><em>X</em> - матрица признаков;</p>
<p><em>b</em> - вектор параметров регрессии.</p>
<p>Задачи множественной регрессии уже очень сложно представить на графике, ведь количество параметров каждого объекта обучающей выборки соответствует измерению, в котором находятся точки данных. Плюс нужно еще одно измерение для целевой переменной. И вместо того, чтобы подбирать оптимальную прямую, мы будем подбирать оптимальную гиперплоскость. Но в целом идея линейной регрессии остается неизменной.</p>
<p>Для удобства примем, что $ x_0^{(i)} = 1 $ для всех i. Другими словами, мы ведем некий суррогатный признак, для всех объектов равный единице. Это никак не сказывается на самой функции гипотезы, это лишь условность обозначения, но это сильно упростит математические выкладки, особенно в матричной форме.</p>
<p>Теперь определим множественную форму функции гипотезы следующим образом, используя несколько признаков. Она очень похожа на парную, но имеет больше входных переменных и, как следствие, больше параметров.</p>
<div class="presentation">
<p>Общий вид модели множественной линейной регрессии:</p>

\[h_b(x) = b_0 + b_1 x_1 + b_2 x_2 + ... + b_n x_n\]

<p>Или в матричной форме:</p>

\[h_b(x) = X \cdot \vec{b}\]
</div>
<p>Используя определение матричного умножения, наша многопараметрическая функция гипотезы может быть кратко представлена в виде: <em>h(x) = B X</em>.</p>
<p>Обратите внимание, что в любой модели линейной регрессии количество параметров на единицу больше количества входных переменных. Это верно для любой линейной модели машинного обучения. Вообще, всегда чем больше признаков, тем больше параметров. Это будет важно для нас позже, когда мы будем говорить о сложности моделей.</p>
<p>Теперь, когда мы знаем виды функции гипотезы, то есть нашей модели, мы можем переходить к следующему шагу: функции ошибки. Мы построим ее по аналогии с функцией ошибки для парной модели. Для множественной регрессии функция ошибки от вектора параметров b выглядит следующим образом:</p>
<div class="presentation">
<p>Функция ошибки для множественной линейной регрессии:</p>

\[J(b) = \frac{1}{2m} \sum_{i=1}^{m} (h_b(x^{(i)}) - y^{(i)})^2\]

<p>Или в матричной форме:</p>

\[J(b) = \frac{1}{2m} (X b - \vec{y})^T (X b - \vec{y})\]
</div>
<p>Обратите внимание, что мы специально не раскрываем выражение \(h_b(x^{(i)})\). Это нужно, чтобы подчеркнуть, что форма функции ошибки не зависит от функции гипотезы, она выражается через нее.</p>
<p>Теперь нам нужно взять производную этой функции ошибки. Здесь уже нужно знать производную самой функции гипотезы, так как:</p>
<div class="presentation">
\[\frac{\partial}{\partial b_i} J = 
\frac{1}{m} \sum_{i=1}^{m} (h_b(x^{(i)}) - y^{(i)}) \cdot \frac{\partial}{\partial b_i} h_b(x^{(i)})\]
</div>
<p>В такой формулировке мы представляем частные производные функции ошибки (градиент) через частную производную функции гипотезы. Это так называемое моделенезависимое представление градиента. Ведь для этой формулы совершенно неважно, какой функцией будет наша гипотеза. Пока она является дифференцируемой, мы можем использовать градиент ее функции ошибки. Именно поэтому метод градиентного спуска работает с любыми аналитическими моделями, и нам не нужно каждый раз заново “переизобретать” математику градиентного спуска, адаптировать ее к каждой конкретной модели машинного обучения. Достаточно изучить этот метод один раз, в общей форме.</p>
<div class="presentation">
<p>Метод градиентного спуска для множественной регрессии определяется следующими уравнениями:</p>
<p>повторять до сходимости:</p>

\[b_0 := b_0 - \alpha \frac{1}{m} \sum_{i=1}^{m} (h_b(x^{(i)}) - y^{(i)}) \cdot x_0^{(i)}\]

\[b_1 := b_1 - \alpha \frac{1}{m} \sum_{i=1}^{m} (h_b(x^{(i)}) - y^{(i)}) \cdot x_1^{(i)}\]

\[b_2 := b_2 - \alpha \frac{1}{m} \sum_{i=1}^{m} (h_b(x^{(i)}) - y^{(i)}) \cdot x_2^{(i)}\]

\[...\]
</div>
<p>Или в матричной форме:</p>
<div class="presentation">
\[b := b - \frac{\alpha}{m} X^T (X b - \vec{y})\]
</div>
<div class="notice--info">
<p>Выводы:</p>
<ol>
<li>Множественная регрессия очень похожа на парную, но с большим количеством признаков.</li>
<li>Для удобства и однообразия, почти всега обозначают $x_0 = 1$.</li>
<li>Признаки уже образуют матрицу, поэтому уравнения множественной регрессии часто приводят в матричной форме, так короче.</li>
<li>Алгоритм градиентного спуска для множественной регрессии точно такой же, как и для парной.</li>
</ol>
</div>
<!-- #### Нормализация признаков

Мы можем ускорить сходимость метода градиентного спуска, получив каждое из наших входных значений примерно в том же диапазоне. Это связано с тем, что b будет быстро сходиться на малых диапазонах и медленно на больших диапазонах, и поэтому будет колебаться неэффективно до оптимального, если переменные очень неравномерны.

Способ предотвратить это - изменить диапазоны наших входных переменных, чтобы они были примерно одинаковыми. В идеале 

-1 ≤ x ≤ 1 или же -0,5 ≤ x ≤ 0,5.

Это не точные требования; мы только пытаемся ускорить процесс. Цель состоит в том, чтобы получить все входные переменные в примерно один из этих диапазонов, дать или взять несколько.

Два метода для этого - масштабирование признаков и нормализация по среднему. Масштабирование признаков заключается в делении входных значений на размах выборки (то есть максимальное значение минус минимальное значение) входной переменной, в результате чего новый диапазон составляет всего 1. Нормализация по среднему включает в себя вычитание среднего значения входной переменной из значений для этой входной переменной, в результате чего новое среднее значение для этой переменной равно нулю. Чтобы реализовать оба этих метода, отрегулируйте свои входные значения, как показано в этой формуле:


$$ x_i = \frac{x_i - \mu_i}{s_i} $$


Где 

$ \mu_i $- среднее значение признака i, а 

$ s_i $ - стандартное отклонение этого признака.


#### Советы по методу градиентного спуска

1. Отладка градиентного спуска. 
Сделайте график с количеством итераций по оси x. Теперь построим функцию стоимости J(b) по числу итераций градиентного спуска. Если J(b) когда-либо возрастает, то, вероятно, вам необходимо уменьшить α.

2. Автоматический тест сходимости. 
Объявите сходимость, если J(b) уменьшится меньше чем на E на одной итерации, где E - некоторое небольшое значение, такое как 10<sup>-3</sup>. Однако на практике трудно выбрать это пороговое значение.
Было доказано, что если скорость обучения α достаточно мала, то J(b) будет уменьшаться на каждой итерации. 

3. Суррогатные признаки
Мы можем улучшить наши функции и форму нашей функции гипотез несколькими способами. Мы можем объединить несколько признаков в один. Например, мы можем объединить x1 и x2 в новый признак x3, взяв x1⋅x2. -->
<h4 id="полиномиальная-регрессия">Полиномиальная регрессия</h4>
<p><img alt="Нелинейная регрессия" class="align-center" src="/assets/images/ml_text/ml1-10.png" style="width: 50%;" title="Нелинейная регрессия"/></p>
<p>Наша функция гипотезы не обязательно должна быть линейной (прямой), если это не соответствует данным. На практике вы не всегда будете иметь данные, которые можно хорошо аппроксимировать линейной функцией. Наглядный пример вы видите на иллюстрации. Вполне очевидно, что в среднем увеличение целевой переменной замедляется с ростом входной переменной. Это значит, что данные демонстрируют нелинейную динамику. И это так же значит, что мы никак не сможем их хорошо приблизить линейной моделью.</p>
<p>Надо подчеркнуть, что это не свидетельствует о несовершенстве наших методов оптимизации. Мы действительно можем найти самую лучшую линейную функцию для данных точек, но проблема в том, что мы всегда выбираем лучшую функцию из некоторого класса функций, в данном случае - линейных. То есть проблема не в алгоритмах оптимизации, а в ограничении самого вида модели.</p>
<p>Но очень бы не хотелось, для каждого нового класса функций изобретать собственный метод оптимизации, поэтому мы постараемся максимально “переиспользовать” те подходы, которые описали выше. И механизм множественной регрессии в этом сильно поможет.</p>
<p>Мы можем изменить поведение или кривую нашей функции гипотезы, сделав ее квадратичной, кубической или любой другой формой.</p>
<p>Например, если наша функция гипотезы 
$ \hat{y} = h_b (x) = b_0 + b_1 x $, 
то мы можем добавить еще один признак, основанный на $ x_1 $, получив квадратичную функцию</p>
<div class="presentation">
\[\hat{y} = h_b (x) = b_0 + b_1 x + b_2 x^2\]
</div>
<p>или кубическую функцию</p>
<div class="presentation">
\[\hat{y} = h_b (x) = b_0 + b_1 x + b_2 x^2 + b_3 x^3\]
</div>
<p>В кубической функции мы по сути ввели два новых признака: 
$ x_2 = x^2, x_3 = x^3 $. 
Точно таким же образом, мы можем создать, например, такую функцию:</p>
<div class="presentation">
\[\hat{y} = h_b (x) = b_0 + b_1 x + b_2 \sqrt{x}\]
</div>
<p>В любом случае, мы из парной линейной функции сделали какую-то другую функцию. И к этой нелинейной функции можно относиться по разному. С одной стороны, это другой класс функций, который обладает нелинейным поведением, а следовательно, может описывать более сложные зависимости в данных. С другой стороны, это линейна функция от нескольких переменных. Только сами эти переменные оказываются в функциональной зависимости друг от друга. Но никто не говорил, что признаки должны быть независимы.</p>
<p>И вот такое представление нелинейной функции как множественной линейной позволяет нам без изменений воспользоваться алгоритмом градиентного спуска для множественной линейной регрессии. Только вместо $ x_2, x_3, … , x_n $ нам нужно будет подставить соответствующие функции от $ x_1 $.</p>
<p style="text-align: center; font-size:0.7em;"><img alt="Полиномиальная регрессия" class="align-center" src="https://upload.wikimedia.org/wikipedia/commons/9/90/Poly-reg-3.png" style="width: 50%;" title="Полиномиальная регрессия"/>
Источник: <a href="https://www.google.com/url?sa=i&amp;url=https%3A%2F%2Fcommons.wikimedia.org%2Fwiki%2FFile%3APoly-reg-3.png&amp;psig=AOvVaw0RpQeJZ6qEk5xxrxustROm&amp;ust=1651936121936000&amp;source=images&amp;cd=vfe&amp;ved=0CAwQjRxqFwoTCMjYvuCTy_cCFQAAAAAdAAAAABAN">Wikimedia</a>.</p>
<p>Очевидно, что нелинейных функций можно придумать бесконечное количество. Поэтому встает вопрос, как выбрать нужный класс функций для решения конкретной задачи. В случае парной регрессии мы можем взглянув на график точек обучающей выборки сделать предположение о том, какой вид нелинейной зависимости связывает входную и целевую переменные. Но если у нас множество признаков, просто так проанализировать график нам не удастся. Поэтому по умолчанию используют полиномиальную регрессию, когда в модель добавляют входные переменные второго, третьего, четвертого и так далее порядков.</p>
<p>Порядок полиномиальной регрессии подбирается в качестве компромисса между качеством получаемой регрессии, и вычислительной сложностью. Ведь чем выше порядок полинома, тем более сложные зависимости он может аппроксимировать. И вообще, чем выше степень полинома, тем меньше будет ошибка при прочих равных. Если степень полинома на единицу меньше количества точек - ошибка будет нулевая. Но одновременно с этим, чем выше степень полинома, тем больше в модели параметров, тем она сложнее и занимает больше времени на обучение. Есть еще вопросы переобучения, но про это мы поговорим позднее.</p>
<p>А что делать, если изначально в модели было несколько признаков? Тогда обычно для определенной степени полинома берутся все возможные комбинации признаком соответствующей степени и ниже. Например:</p>
<div class="presentation">
<p>Для регрессии с двумя признаками.</p>
<p>Линейная модель (полином степени 1):</p>

\[h_b (x) = b_0 + b_1 x_1 + b_2 x_2\]

<p>Квадратичная модель (полином степени 2):</p>

\[h_b (x) = b_0 + b_1 x + b_2 x_2 + b_3 x_1^2 + b_4 x_2^2 + b_5 x_1 x_2\]

<p>Кубическая модель (полином степени 3):</p>

\[\hat{y} = h_b (x) = b_0 + b_1 x_1 + b_2 x_2 + b_3 x_1^2 + b_4 x_2^2 + b_5 x_1 x_2 + b_6 x_1^3 + b_7 x_2^3 + b_7 x_1^2 x_2 + b_8 x_1 x_2^2\]
</div>
<p>При этом количество признаков и, соответственно, количество параметров растет экспоненциально с ростом степени полинома. Поэтому полиномиальные модели обычно очень затратные в обучении при больших степенях. Но полиномы высоких степеней более универсальны и могут аппроксимировать более сложные данные лучше и точнее.</p>
<div class="notice--info">
<p>Выводы:</p>
<ol>
<li>Данные в датасете не всегда располагаются так, что их хорошо может описывать линейная функция.</li>
<li>Для описания нелинейных зависимостей нужна более сложная, нелинейная модель.</li>
<li>Чтобы не изобретать алгоритм обучения заново, можно просто ввести в модель суррогатные признаки.</li>
<li>Суррогатный признак - это новый признак, который считается из существующих атрибутов.</li>
<li>Чаще всего используют полиномиальную регрессию - это когда в модель вводят полиномиальные признаки - степени существующих атрибутов.</li>
<li>Обычно берут все комбинации факторов до какой-то определенной степени полинома.</li>
<li>Полиномиальная регрессия может аппроксимировать любую функцию, нужно только подобрать степень полинома.</li>
<li>Чем больше степень полиномиальной регрессии, тем она сложнее и универсальнее, но вычислительно сложнее (экспоненциально).</li>
</ol>
</div>
<!-- #### Нормальное уравнение

«Нормальное уравнение» - это метод нахождения оптимальных параметров регрессии без итераций:

$$ b = (X^T X)^{-1} X^T y $$

Нет необходимости выполнять масштабирование признаков, если мы решаем регрессию с помощью нормального уравнения.

Метод решения через нормальное уравнение имеет ряд преимуществ по сравнению с методом градиентного спуска:

1. Нет необходимости в нормализации признаков;
2. Не нужно выбирать скорость обучения;
3. Не требует вычисления частных производных функции ошибки;

Однако, у него есть и недостатки:

1. Имеет асимптотику O(n<sup>3</sup>) по сравнению с O(n<sup>2</sup>) у градиентного спуска. Поэтому довольно медленно работает при больших n.
2. Требует вычисления обратной матрицы. В некоторых случаях матрица $X^T X$ может быть вырожденной, что затруднит использование нормального уравнения. -->
<h3 id="практическое-построение-регрессии">Практическое построение регрессии</h3>
<h4 id="как-должны-быть-представлены-данные-для-машинного-обучения">Как должны быть представлены данные для машинного обучения?</h4>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
</pre></td><td class="rouge-code"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'x.csv'</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.46</span><span class="p">,</span> <span class="mf">1.13</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.30</span><span class="p">,</span> <span class="mf">1.74</span><span class="p">,</span> <span class="mf">0.04</span><span class="p">,</span> 
    <span class="o">-</span><span class="mf">0.61</span><span class="p">,</span> <span class="mf">0.32</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.76</span><span class="p">,</span> <span class="mf">0.58</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.10</span><span class="p">,</span> 
     <span class="mf">0.87</span><span class="p">,</span> <span class="mf">1.62</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.53</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.25</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.07</span><span class="p">,</span> 
    <span class="o">-</span><span class="mf">0.38</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.17</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.32</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.06</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.88</span><span class="p">,</span> <span class="p">])</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'y.csv'</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mf">101.16</span><span class="p">,</span> <span class="mf">78.44</span><span class="p">,</span> <span class="o">-</span><span class="mf">159.24</span><span class="p">,</span> <span class="mf">120.72</span><span class="p">,</span> <span class="mf">2.92</span><span class="p">,</span> 
    <span class="o">-</span><span class="mf">42.33</span><span class="p">,</span> <span class="mf">22.07</span><span class="p">,</span> <span class="o">-</span><span class="mf">52.67</span><span class="p">,</span> <span class="mf">40.32</span><span class="p">,</span> <span class="o">-</span><span class="mf">76.10</span><span class="p">,</span> 
     <span class="mf">59.88</span><span class="p">,</span> <span class="mf">112.38</span><span class="p">,</span> <span class="o">-</span><span class="mf">36.54</span><span class="p">,</span> <span class="o">-</span><span class="mf">17.25</span><span class="p">,</span> <span class="o">-</span><span class="mf">74.24</span><span class="p">,</span> 
    <span class="o">-</span><span class="mf">26.57</span><span class="p">,</span> <span class="o">-</span><span class="mf">11.93</span><span class="p">,</span> <span class="o">-</span><span class="mf">22.31</span><span class="p">,</span> <span class="o">-</span><span class="mf">142.54</span><span class="p">,</span> <span class="o">-</span><span class="mf">60.74</span><span class="p">,])</span>

<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>
<p><img alt="Данные для регрессии" class="align-center" src="/assets/images/ml_text/ml1-11.png" style="width: 50%;" title="Данные для регрессии"/></p>
<!-- #### Как работает метод машинного обучения "на пальцах"?

```py
class hypothesis(object):
    """Модель парной линейной регрессии"""
    def __init__(self):
        self.b0 = 0
        self.b1 = 0
    def predict(self, x):
        return self.b0 + self.b1 * x
    def error(self, X, Y):    
        return sum((self.predict(X) - Y)**2) / (2 * len(X)) 
    def BGD(self, X, Y):  
        alpha = 0.1
        dJ0 = sum(self.predict(X) - Y) /len(X)
        dJ1 = sum((self.predict(X) - Y) * X) /len(X)
        self.b0 -= alpha * dJ0
        self.b1 -= alpha * dJ1

hyp = hypothesis()
print(hyp.predict(0))
print(hyp.predict(100))
J = hyp.error(x, y)
print("initial error:", J)
hyp.BGD(x, y)
J = hyp.error(x, y)
print("error after gradient descent:", J)
``` -->
<h4 id="как-оценить-качество-регрессионной-модели">Как оценить качество регрессионной модели?</h4>
<!-- ```py
    def BGD(self, X, Y, alpha=0.1, accuracy=0.01, max_steps=1000):
        steps, errors = [], []
        step = 0        
        old_err = hyp.error(X, Y)
        new_err = hyp.error(X, Y) - 1
        dJ = 1
        while (dJ > accuracy) and (step < max_steps):
            dJ0 = sum(self.predict(X) - Y) /len(X)
            dJ1 = sum((self.predict(X) - Y) * X) /len(X)
            self.b0 -= alpha * dJ0
            self.b1 -= alpha * dJ1            
            old_err = new_err
            new_err = hyp.error(X, Y)
            dJ = abs(old_err - new_err) 
            step += 1            
            steps.append(step)
            errors.append(new_err)
        return steps, errors
```

![Обученная регрессия](/assets/images/ml_text/ml1-12.png "Обученная регрессия"){: .align-center style="width: 50%;"} -->
<p><img alt="Прогресс обучения" class="align-center" src="/assets/images/ml_text/ml1-13.png" style="width: 50%;" title="Прогресс обучения"/></p>
<h4 id="как-применять-регрессию-с-использованием-scikit-learn">Как применять регрессию с использованием scikit-learn?</h4>
<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
</pre></td><td class="rouge-code"><pre><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">linear_model</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="n">reg</span> <span class="o">=</span> <span class="n">linear_model</span><span class="p">.</span><span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">reg</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">reg</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>

<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_error</span><span class="p">,</span> <span class="n">r2_score</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">reg</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Коэффициенты: </span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">reg</span><span class="p">.</span><span class="n">coef_</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Среднеквадратичная ошибка: %.2f"</span> <span class="o">%</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Коэффициент детерминации: %.2f"</span> <span class="o">%</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>

<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">9</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">"black"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">"blue"</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</pre></td></tr></tbody></table></code></pre></div></div>
<p><img alt="Библиотечная регрессия" class="align-center" src="/assets/images/ml_text/ml1-14.png" style="width: 50%;" title="Библиотечная регрессия"/></p>
</div>
<header class="caption">
<h1>Регрессия как задача машинного обучения</h1>
<!-- <p>Yours Truly, Famous Inc.</p> -->
</header>
<section class="slide">
<h2 class="shout">Регрессия как задача машинного обучения</h2>
</section>
<footer class="badge">
<a href="https://github.com/shower/shower">Build with shower</a>
</footer>
<script src="/assets/shower/shower.js"></script>
<!-- Copyright © 3000 Yours Truly, Famous Inc. -->
<script type="text/javascript">
        
        const content = document.querySelector('#temp');
        const childern = content.childNodes;

        let current_slide;
        let points;
        let code;
        let image;
        let misc;

        function commit() {
            if (current_slide) {

                const elems = [image, code, points, misc];

                let slide;

                elems.forEach(elem => {
                    if (elem) {
                        // console.log("ИТЕРАЦИЯ " + current_slide);
                        // console.log([image, code, points, misc]);

                        slide = document.createElement('section');
                        slide.className = "slide";
                        let slide_header = document.createElement('h2');
                        slide_header.innerHTML = current_slide;
                        slide.appendChild(slide_header);

                        slide.appendChild(elem);

                        document.body.appendChild(slide);

                        fit_in_slide(elem);
                    }
                });

                misc = undefined;
                points = undefined;
                image = undefined;
                code = undefined;
            }
        }

        function fit_in_slide(element) {
            console.log("ИТЕРАЦИЯ " + current_slide);
            console.log(element);

            let ratio = Math.min(
            	550 / element.offsetHeight,
            	// 1600 / element.offsetWidth,
            	);


            let new_size = Math.sqrt(ratio) / 1.2;
            if (new_size > 2.5) {
                new_size = 2.5
            }
            element.style["font-size"] = new_size + "em";

            new_size = Math.pow(ratio, 1.1) * 12;
            if (new_size > 30) {
                new_size = 30
            }

            ratio = Math.min(
            	550 / element.offsetHeight,
            	1600 / element.offsetWidth,
            	);

            new_size = Math.pow(ratio, 1.1) * 12;
            if (new_size > 30) {
                new_size = 30
            }

            console.log(element.innerHTML);            
            console.log(element.querySelectorAll("*"));            
            console.log(element.querySelectorAll("pre"));

            element.querySelectorAll("pre").forEach(e => {
                e.style["font-size"] = new_size + "px";
                e.style["line-height"] = new_size * 1.2 + "px";
            });

            element.querySelectorAll("span").forEach(e => {
            	console.log("found");
                e.style["font-size"] = new_size + "px";
                e.style["line-height"] = new_size * 1.2 + "px";
            });

            console.log(
                // realHeight, ratio, 
                new_size, 
                element.offsetHeight,
                element.offsetWidth);

            return element;
        }

        childern.forEach(elem => {
            if (elem.tagName == "H3") {
                commit();
                let slide = document.createElement('section');
                slide.className = "slide";
                let slide_header = document.createElement('h2');
                slide_header.className = "shout shrink"
                slide_header.innerHTML = elem.innerHTML;
                slide.appendChild(slide_header);

                // slide.appendChild(elem);

                document.body.appendChild(slide);
            }

            if (elem.tagName == "H3" || elem.tagName == "H4") {
                commit();
                current_slide = elem.innerHTML;
            }

            else if (elem.tagName == "DIV" && elem.classList.contains("notice--info")) {
                let list = elem.getElementsByTagName('ol')[0];

                list.childNodes.forEach(elem => {
                    elem.className = "next";
                });

                points = list;
                // points = fit_in_slide(points);
            } 

            else if (elem.tagName == "DIV" && elem.classList.contains("highlighter-rouge")) {
                code = elem;
                commit()
                // code = fit_in_slide(code);
            } 

            else if (elem.tagName == "DIV" && elem.classList.contains("presentation")) {
                misc = elem;
                // misc = fit_in_slide(misc);
                commit();
            } 

            else if (elem.tagName == "P" && elem.getElementsByTagName('img').length > 0) {
                image = elem.getElementsByTagName('img')[0];
                image.style.width = "auto";
                commit();
            } 
        });

        commit();

        content.remove();

    </script>
<div class="progress"></div>
<script src="/assets/js/main.min.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-1K09X3NDBE"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-1K09X3NDBE', { 'anonymize_ip': false});
</script>
<!-- Yandex.Metrika counter -->
<script type="text/javascript">
   (function(m,e,t,r,i,k,a){m[i]=m[i]||function(){(m[i].a=m[i].a||[]).push(arguments)};
   m[i].l=1*new Date();k=e.createElement(t),a=e.getElementsByTagName(t)[0],k.async=1,k.src=r,a.parentNode.insertBefore(k,a)})
   (window, document, "script", "https://mc.yandex.ru/metrika/tag.js", "ym");

   ym(77706580, "init", {
        clickmap:true,
        trackLinks:true,
        accurateTrackBounce:true
   });
</script>
<noscript><div><img alt="" src="https://mc.yandex.ru/watch/77706580" style="position:absolute; left:-9999px;"/></div></noscript>
<!-- /Yandex.Metrika counter -->
<script async="" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML" type="text/javascript">
</script>
<script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     extensions: ["tex2jax.js"],
     jax: ["input/TeX", "output/HTML-CSS"],
     tex2jax: {
       inlineMath: [ ['$','$'], ["\\(","\\)"] ],
       displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
       processEscapes: true
     },
     "HTML-CSS": { availableFonts: ["TeX"] }
   });
</script>
<script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
</body>
</html>
