Создал проект Кожевников Николай, студент 1-ого курса магистратуры направления ФТиАД Высшей школы экономики. Web-crawler необходимо было написать и выложить на github в качестве домашнего задания. Ниже опишу, как загрзить проект на свой компьютер и запустить его. Приятного использования!

1. Зайти в ту директорию, в которую вы хотите сохранить этот проект
2. Через терминал создать свой репозиторий при помощи git init
3. Клонируем этот репозиторий в свой:  git clone https://github.com/kozhevnikovnv/web_crawler_hse
4. Далее устанавливаем пакеты из requirements.txt при помощи: python pip install requirements.txt
5. И при помощи команды: python crawler_kozhevnikov.py запускаем crawler
6. В файл urls.txt будут помещены все номера и адреса страниц, которые мы парсили, а в папку data - содержимое этих страниц (id страниц в папке data совпадает с номерами страниц в файле urls.txt)
7. Поздравляю! Вы запустили и использовали мой парсер, спасибо!

Надеюсь, все получится